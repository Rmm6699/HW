{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rmm6699/HW/blob/master/W8_TA_RecSysGNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2xJf1plqWhL"
      },
      "source": [
        "# 永豐銀行 AI人才培育課程--個人化商品推薦系統 #3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slsNOdtWqWhN"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import Data, Dataset\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch_geometric.nn import GCNConv, global_mean_pool\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tQtaNWEpqWhO"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./data/raw/yoochoose-clicks.dat')\n",
        "buy_item_dict = np.load('./data/raw/yoochoose-buys.npy', allow_pickle=True).item()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FIuVouwIqWhO",
        "outputId": "34521add-e46f-4792-998a-08891f6e653a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>user_id</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>item_id</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10219</td>\n",
              "      <td>2014-04-07T18:02:10.363Z</td>\n",
              "      <td>1768</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10219</td>\n",
              "      <td>2014-04-07T18:07:21.344Z</td>\n",
              "      <td>1118</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10219</td>\n",
              "      <td>2014-04-07T18:12:10.800Z</td>\n",
              "      <td>711</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11147</td>\n",
              "      <td>2014-04-03T15:08:48.448Z</td>\n",
              "      <td>1761</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11147</td>\n",
              "      <td>2014-04-03T15:10:32.687Z</td>\n",
              "      <td>241</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5376</th>\n",
              "      <td>11289324</td>\n",
              "      <td>2014-09-28T12:01:51.100Z</td>\n",
              "      <td>2615</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5377</th>\n",
              "      <td>11289324</td>\n",
              "      <td>2014-09-28T12:02:22.153Z</td>\n",
              "      <td>2235</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5378</th>\n",
              "      <td>11303431</td>\n",
              "      <td>2014-09-24T10:32:54.219Z</td>\n",
              "      <td>2296</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5379</th>\n",
              "      <td>11303431</td>\n",
              "      <td>2014-09-24T10:34:02.287Z</td>\n",
              "      <td>2296</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5380</th>\n",
              "      <td>11303431</td>\n",
              "      <td>2014-09-24T10:34:02.425Z</td>\n",
              "      <td>2296</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5381 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       user_id                 timestamp  item_id  category\n",
              "0        10219  2014-04-07T18:02:10.363Z     1768         0\n",
              "1        10219  2014-04-07T18:07:21.344Z     1118         0\n",
              "2        10219  2014-04-07T18:12:10.800Z      711         0\n",
              "3        11147  2014-04-03T15:08:48.448Z     1761         0\n",
              "4        11147  2014-04-03T15:10:32.687Z      241         0\n",
              "...        ...                       ...      ...       ...\n",
              "5376  11289324  2014-09-28T12:01:51.100Z     2615        20\n",
              "5377  11289324  2014-09-28T12:02:22.153Z     2235        20\n",
              "5378  11303431  2014-09-24T10:32:54.219Z     2296         5\n",
              "5379  11303431  2014-09-24T10:34:02.287Z     2296         5\n",
              "5380  11303431  2014-09-24T10:34:02.425Z     2296         5\n",
              "\n",
              "[5381 rows x 4 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.drop(4).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UVwLkjjmqWhP",
        "outputId": "c07891d8-30d4-4ae2-dc0b-149d574ce29b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{124227: [864, 864],\n",
              " 234892: [1204, 1204],\n",
              " 304679: [1164],\n",
              " 358676: [1512, 1489, 1489, 1512],\n",
              " 468904: [865, 354],\n",
              " 484992: [334],\n",
              " 504357: [862, 1338],\n",
              " 509067: [1978, 1989, 1983],\n",
              " 612124: [864],\n",
              " 826473: [393],\n",
              " 1047341: [988],\n",
              " 1061114: [1895, 1372],\n",
              " 1132331: [540],\n",
              " 1549606: [1568, 1045],\n",
              " 1610752: [1669],\n",
              " 1804214: [828],\n",
              " 2166732: [1699, 1742, 1494, 694, 1659, 1820],\n",
              " 2455183: [1627, 1668, 1372, 1374],\n",
              " 2619711: [68],\n",
              " 2676913: [160],\n",
              " 2691321: [1741, 553, 1673, 1703],\n",
              " 2775817: [1215, 1215, 1206],\n",
              " 2806516: [443, 1647],\n",
              " 2811569: [475, 1702, 474],\n",
              " 2992271: [2645, 2645],\n",
              " 3096232: [965, 960],\n",
              " 3413956: [1413, 1409, 1415],\n",
              " 3459484: [1252],\n",
              " 4487171: [1905, 2050],\n",
              " 4506726: [180, 181, 181, 180],\n",
              " 4533094: [1760, 870, 1498],\n",
              " 4534956: [2160, 1792, 1967],\n",
              " 4888738: [1810, 1811, 1811, 1802, 1655],\n",
              " 5066864: [1448, 1483, 1720],\n",
              " 5177043: [863],\n",
              " 5286913: [2071, 2016],\n",
              " 5307603: [1682],\n",
              " 5439463: [1606],\n",
              " 5452941: [380, 402, 381, 1285, 1797, 1880, 1885, 556, 2026],\n",
              " 5462764: [2085, 1524, 866, 2093],\n",
              " 5661471: [2031, 2022],\n",
              " 5777773: [2135, 1867, 1980],\n",
              " 5863482: [1011, 342],\n",
              " 5927622: [461],\n",
              " 5948402: [2095, 1631, 2218, 1634],\n",
              " 6039079: [2087],\n",
              " 6076198: [2132, 2137, 2141, 2128, 2126],\n",
              " 6208269: [2194, 2214, 1195, 1592, 1662],\n",
              " 6279132: [2238, 2192],\n",
              " 6410232: [2116],\n",
              " 6771429: [1952],\n",
              " 6800672: [2033],\n",
              " 6932932: [2254, 2199, 2256, 2081, 2246, 2329],\n",
              " 6998791: [1960, 2150, 890],\n",
              " 7142562: [2256, 2261, 2255, 2254, 2249],\n",
              " 7214476: [334, 2271, 2274],\n",
              " 7290634: [849, 2220, 1836, 2276],\n",
              " 7994408: [1697],\n",
              " 8190006: [2364, 2378, 2388],\n",
              " 8458198: [1899, 2286, 2279, 1268, 871, 1721, 1311],\n",
              " 8527629: [2419, 2349],\n",
              " 8628816: [2437, 2427, 2051, 2215, 2424],\n",
              " 8650866: [2461],\n",
              " 8729431: [2457, 2433, 2446, 2444],\n",
              " 8796033: [2403, 2104, 831],\n",
              " 8879231: [2421, 2424, 2417],\n",
              " 9029579: [1001],\n",
              " 9240816: [1224],\n",
              " 9290819: [2468, 2156],\n",
              " 9658306: [2432, 2443],\n",
              " 9709459: [2420],\n",
              " 9757551: [278],\n",
              " 9794414: [1345, 1370],\n",
              " 9806473: [1265, 2518, 2489, 2501, 2481, 1143, 2401, 2487],\n",
              " 10075249: [2522, 2507, 1831, 2511],\n",
              " 10095198: [47, 2562],\n",
              " 10150807: [2508, 2507, 2510, 2510],\n",
              " 10196444: [2483, 2482, 2510],\n",
              " 10568779: [2446, 2570, 908, 910],\n",
              " 10666057: [2529, 2555, 2547],\n",
              " 10808948: [2530, 2533, 2527],\n",
              " 10991362: [2643, 2582, 2423],\n",
              " 10997731: [2422, 2575],\n",
              " 11187803: [2572, 2566, 2465, 2580],\n",
              " 11209009: [1711],\n",
              " 11276347: [2595, 2423, 2643, 2574],\n",
              " 11463976: [203]}"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "buy_item_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ezQ1ISEqWhQ"
      },
      "source": [
        "## 1. Create Own Dataset\n",
        "<img src=\"./data/image/Graph_data_.png\" width=\"80%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxdrYbf6qWhQ"
      },
      "outputs": [],
      "source": [
        "class YooChooseDataset(Dataset):\n",
        "    def __init__(self, root):\n",
        "        super().__init__(root)\n",
        "        self.data, self.num_items, self.num_categories = torch.load(self.processed_paths[0])\n",
        "\n",
        "    @property\n",
        "    def raw_file_names(self):\n",
        "        return ['yoochoose-clicks.dat', 'yoochoose-buys.npy']\n",
        "    \n",
        "    @property\n",
        "    def processed_file_names(self):\n",
        "        return ['yoochoose-clicks-processed.dataset']\n",
        "\n",
        "    def download(self):\n",
        "        pass\n",
        "\n",
        "    def process(self):\n",
        "        \n",
        "        df = pd.read_csv(self.raw_paths[0])\n",
        "        buy_item_dict = np.load(self.raw_paths[1], allow_pickle=True).item()\n",
        "        \n",
        "        num_items = df.item_id.nunique()\n",
        "        num_categories = df.category.nunique()\n",
        "        \n",
        "        # process by user_id\n",
        "        graph_list = []\n",
        "        grouped = df.groupby('user_id')\n",
        "        for user_id, group in tqdm(grouped):\n",
        "            # 1. Create Graph edges\n",
        "            # Re-encode the item_id\n",
        "            le = LabelEncoder()\n",
        "            group['local_item_id'] = le.fit_transform(group.item_id) # Create new column for new item ids\n",
        "            \n",
        "            # If Purchase order = [1,2,3,4], source_nodes = [1,2,3], target_nodes = [2,3,4]\n",
        "            source_nodes = group.local_item_id.values[:-1]\n",
        "            target_nodes = group.local_item_id.values[1:]\n",
        "            edge_index = torch.LongTensor(np.array([source_nodes, target_nodes]))\n",
        "            \n",
        "            # 2. Create node_features\n",
        "            temp_features = group.loc[group.user_id==user_id,['local_item_id','item_id','category']].sort_values('local_item_id')\n",
        "            node_features = temp_features[['item_id','category']].drop_duplicates().values\n",
        "            node_features = torch.LongTensor(node_features)\n",
        "            \n",
        "            # 3. Create Labels\n",
        "            if user_id in buy_item_dict:\n",
        "                positive_indices = le.transform(buy_item_dict[user_id]) # buy_item_dict {468904(user_id):[865, 354](item_ids)}\n",
        "                label = np.zeros(len(node_features))\n",
        "                label[positive_indices] = 1 # [0, 0, 1, 0]\n",
        "            else:\n",
        "                label = [0] * len(node_features) # [0, 0, 0, 0]\n",
        "            y = torch.FloatTensor(label)\n",
        "            \n",
        "            # 4. Combine node_features, edge_index and labels into Data(x, edge_index, y)\n",
        "            data = Data(x=node_features, edge_index=edge_index, y=y) # Represent a graph\n",
        "            graph_list.append(data)\n",
        "            \n",
        "        # 5. Save processed data\n",
        "        torch.save((graph_list, num_items, num_categories), self.processed_paths[0])\n",
        "        \n",
        "    def len(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def get(self, idx):\n",
        "        return self.data[idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ThR0cpmpqWhR"
      },
      "outputs": [],
      "source": [
        "dataset = YooChooseDataset('./data')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fCFsYFXfqWhR",
        "outputId": "ec2ac663-2a23-4cfb-8f5e-ff0acc2a9e88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Data(x=[3, 2], edge_index=[2, 2], y=[3]),\n",
              " Data(x=[4, 2], edge_index=[2, 6], y=[4]),\n",
              " Data(x=[3, 2], edge_index=[2, 2], y=[3]),\n",
              " Data(x=[3, 2], edge_index=[2, 2], y=[3]),\n",
              " Data(x=[4, 2], edge_index=[2, 5], y=[4]),\n",
              " Data(x=[2, 2], edge_index=[2, 8], y=[2]),\n",
              " Data(x=[4, 2], edge_index=[2, 3], y=[4]),\n",
              " Data(x=[9, 2], edge_index=[2, 8], y=[9]),\n",
              " Data(x=[12, 2], edge_index=[2, 13], y=[12]),\n",
              " Data(x=[1, 2], edge_index=[2, 2], y=[1])]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.data[:10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "njjhBsogqWhR",
        "outputId": "e291b3e2-5b47-4713-8878-f72db177b1dc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2646, 21)"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.num_items, dataset.num_categories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hEq9t7xtqWhS",
        "outputId": "d3cf2435-9ba6-4a6b-9447-883f23c3786c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(800, 100, 100)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset = dataset.shuffle()\n",
        "one_tenth_length = int(len(dataset) * 0.1)\n",
        "train_dataset = dataset[:one_tenth_length * 8]\n",
        "val_dataset = dataset[one_tenth_length*8:one_tenth_length * 9]\n",
        "test_dataset = dataset[one_tenth_length*9:]\n",
        "\n",
        "len(train_dataset), len(val_dataset), len(test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egpVs1lnqWhS"
      },
      "outputs": [],
      "source": [
        "batch_size= 128\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size)\n",
        "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtHeUBrYqWhS"
      },
      "source": [
        "## 2. Build GNN Model\n",
        "<img src=\"./data/image/GNN.png\" width=\"80%\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dA3dwGfwqWhT"
      },
      "outputs": [],
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, embed_dim, num_items, num_categories):\n",
        "        super(Net, self).__init__()\n",
        "        \n",
        "        self.item_embedding = torch.nn.Embedding(num_embeddings=num_items, embedding_dim=embed_dim)\n",
        "        self.category_embedding = torch.nn.Embedding(num_embeddings=num_categories, embedding_dim=embed_dim)\n",
        "        \n",
        "        # GNN Layers\n",
        "        self.conv1 = GCNConv(embed_dim * 2, embed_dim)\n",
        "        self.conv2 = GCNConv(embed_dim, embed_dim)\n",
        "        \n",
        "        # Readout Layers\n",
        "        self.linear1 = torch.nn.Linear(embed_dim, embed_dim*2)\n",
        "        self.linear2 = torch.nn.Linear(embed_dim*2, embed_dim)\n",
        "  \n",
        "    def forward(self, x, edge_index, batch):\n",
        "        \n",
        "        # x.shape, edge_index.shape, batch.shape\n",
        "        # torch.Size([n_items in this batch, 1, 2]) torch.Size([2, |E|]) torch.Size([n_items in this batch])\n",
        "        # n_items in this batch : Only count the number of items in this batch\n",
        "        \n",
        "        # 1. process sparse features into dense embeddings\n",
        "        item_id = x[:, 0]\n",
        "        category = x[:, 1]\n",
        "        emb_item = self.item_embedding(item_id) # torch.Size([n_items in this batch, 128])\n",
        "        emb_category = self.category_embedding(category) # torch.Size([n_items in this batch, 128])\n",
        "        x = torch.cat([emb_item, emb_category], dim=1) # torch.Size([n_items in this batch, 256(128+128)])\n",
        "        \n",
        "        # 2. put node feature and edge_index into GNN layer and activation function (Layer1)\n",
        "        x = F.relu(self.conv1(x, edge_index)) # torch.Size([n_items in this batch, 128])\n",
        "        \n",
        "        # 3. Conduct mean-pooling by user's id (pooling Layer1)\n",
        "        x1 = global_mean_pool(x, batch) # torch.Size([128, 128]) \n",
        "        \n",
        "        # 4. put outputs of Layer1 and edge_index into GNN layer and activation function (Layer2)\n",
        "        x = F.relu(self.conv2(x, edge_index)) # torch.Size([n_items in this batch, 128])\n",
        "        \n",
        "        # 5. Conduct mean-pooling by user's id (pooling Layer2)\n",
        "        x2 = global_mean_pool(x, batch) # torch.Size([128, 128])\n",
        "        \n",
        "        # 6. Combine the results from pooling Layer1 and pooling Layer2\n",
        "        x = x1 + x2\n",
        "\n",
        "        # 7. Readout layer\n",
        "        x = F.relu(self.linear1(x))\n",
        "        x = F.dropout(x, p=0.5, training=self.training)\n",
        "        x = self.linear2(x)\n",
        "        # x represent the user embedding which includes information about the purchase history of the user \n",
        "        \n",
        "        scores = []\n",
        "        for i in range(x.size(0)):\n",
        "            user_embeddings = x[i, :] # torch.Size([128])\n",
        "            item_embeddings = emb_item[batch == i] # torch.Size([n_items, 128])\n",
        "            score = torch.matmul(item_embeddings, user_embeddings) #　torch.Size([n_items])\n",
        "            scores.append(score)\n",
        "              \n",
        "        x = torch.cat(scores, dim=0) # torch.Size([n_items])\n",
        "\n",
        "        return torch.sigmoid(x) # to 0~1 socre"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6sLF6rjvqWha"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "\n",
        "model = Net(embed_dim=128, num_items=dataset.num_items, num_categories=dataset.num_categories).to(device)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.nn.BCELoss()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0MXvbUFqWha"
      },
      "source": [
        "## 3. Train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kxw8QmuCqWha"
      },
      "outputs": [],
      "source": [
        "def train():\n",
        "    model.train()\n",
        "    loss_all = 0\n",
        "    for data in train_loader:\n",
        "        data = data.to(device)\n",
        "        x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "        y_ture = data.y.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        y_pred = model(x, edge_index, batch)\n",
        "    \n",
        "        loss = criterion(y_pred, y_ture)\n",
        "        loss.backward()\n",
        "        loss_all += data.num_graphs * loss.item()\n",
        "        optimizer.step()\n",
        "\n",
        "    return data, loss_all / len(train_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gb9cn-8BqWhb"
      },
      "outputs": [],
      "source": [
        "def evaluate(loader):\n",
        "    model.eval()\n",
        "    \n",
        "    predictions = []\n",
        "    labels = []\n",
        "    with torch.no_grad():\n",
        "        for data in loader:\n",
        "            data = data.to(device)\n",
        "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
        "            y_pred = model(x, edge_index, batch).detach().cpu().numpy()\n",
        "\n",
        "            y_true = data.y.detach().cpu().numpy()\n",
        "            predictions.append(y_pred)\n",
        "            labels.append(y_true)\n",
        "\n",
        "    predictions = np.hstack(predictions)\n",
        "    labels = np.hstack(labels)\n",
        "    \n",
        "    return roc_auc_score(labels, predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SJaAuTzvqWhb",
        "outputId": "b7493d6e-9a4b-4a52-dccb-537970e002a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 000, Loss: 1.08964, Train Auc: 0.59776, Val Auc: 0.49523, Test Auc: 0.41228\n",
            "Epoch: 001, Loss: 0.65176, Train Auc: 0.66775, Val Auc: 0.53180, Test Auc: 0.48776\n",
            "Epoch: 002, Loss: 0.56379, Train Auc: 0.72467, Val Auc: 0.55016, Test Auc: 0.47782\n",
            "Epoch: 003, Loss: 0.51267, Train Auc: 0.77348, Val Auc: 0.55812, Test Auc: 0.47815\n",
            "Epoch: 004, Loss: 0.46621, Train Auc: 0.80769, Val Auc: 0.54898, Test Auc: 0.49104\n",
            "Epoch: 005, Loss: 0.40988, Train Auc: 0.83709, Val Auc: 0.53328, Test Auc: 0.48962\n",
            "Epoch: 006, Loss: 0.37364, Train Auc: 0.87164, Val Auc: 0.55477, Test Auc: 0.49192\n",
            "Epoch: 007, Loss: 0.33365, Train Auc: 0.90247, Val Auc: 0.57297, Test Auc: 0.49421\n",
            "Epoch: 008, Loss: 0.28783, Train Auc: 0.92766, Val Auc: 0.58313, Test Auc: 0.51802\n",
            "Epoch: 009, Loss: 0.26544, Train Auc: 0.94826, Val Auc: 0.58859, Test Auc: 0.52884\n",
            "Epoch: 010, Loss: 0.22855, Train Auc: 0.96212, Val Auc: 0.56727, Test Auc: 0.52272\n",
            "Epoch: 011, Loss: 0.21142, Train Auc: 0.97256, Val Auc: 0.57336, Test Auc: 0.53605\n",
            "Epoch: 012, Loss: 0.18772, Train Auc: 0.98111, Val Auc: 0.57875, Test Auc: 0.54796\n",
            "Epoch: 013, Loss: 0.16662, Train Auc: 0.98735, Val Auc: 0.60273, Test Auc: 0.51923\n",
            "Epoch: 014, Loss: 0.15866, Train Auc: 0.99280, Val Auc: 0.57883, Test Auc: 0.51584\n",
            "Epoch: 015, Loss: 0.14030, Train Auc: 0.99436, Val Auc: 0.56312, Test Auc: 0.54763\n",
            "Epoch: 016, Loss: 0.12305, Train Auc: 0.99665, Val Auc: 0.54891, Test Auc: 0.54708\n",
            "Epoch: 017, Loss: 0.11682, Train Auc: 0.99763, Val Auc: 0.58141, Test Auc: 0.55145\n",
            "Epoch: 018, Loss: 0.10093, Train Auc: 0.99813, Val Auc: 0.57484, Test Auc: 0.56139\n",
            "Epoch: 019, Loss: 0.09107, Train Auc: 0.99836, Val Auc: 0.56180, Test Auc: 0.55528\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(20):\n",
        "    d, loss = train()\n",
        "    train_acc = evaluate(train_loader)\n",
        "    val_acc = evaluate(val_loader)    \n",
        "    test_acc = evaluate(test_loader)\n",
        "    print('Epoch: {:03d}, Loss: {:.5f}, Train Auc: {:.5f}, Val Auc: {:.5f}, Test Auc: {:.5f}'.\n",
        "          format(epoch, loss, train_acc, val_acc, test_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w_5KeNBKqWhb"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}